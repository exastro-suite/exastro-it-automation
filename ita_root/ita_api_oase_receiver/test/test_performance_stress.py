#   Copyright 2025 NEC Corporation
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

import pytest
import time
from unittest.mock import patch, MagicMock
from flask import Flask, g

from controllers.oase_controller import add_notification_queue


class TestPerformanceAndStress:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """å„ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®å‰ã«å®Ÿè¡Œã•ã‚Œã‚‹åˆæœŸåŒ–å‡¦ç†"""
        self.app = Flask(__name__)
        self.app_context = self.app.app_context()
        self.app_context.push()

        g.applogger = MagicMock()
        g.appmsg = MagicMock()
        g.applogger.info = MagicMock()
        g.applogger.warning = MagicMock()
        g.applogger.error = MagicMock()

    def teardown_method(self):
        """å„ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®å¾Œã«å®Ÿè¡Œã•ã‚Œã‚‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        self.app_context.pop()

    @pytest.mark.slow
    @patch('controllers.oase_controller.OASE')
    def test_massive_data_volume_performance(self, mock_oase):
        """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # 50,000ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        massive_recieve_list = []
        massive_duplicate_list = []

        for i in range(25000):
            massive_recieve_list.append({
                "event_id": f"massive_recieve_{i:06d}",
                "message": f"Massive recieve event {i}",
                "timestamp": f"2025-01-01T{i%24:02d}:{i%60:02d}:{i%60:02d}Z",
                "data": {
                    "source": f"source_{i%100}",
                    "category": f"category_{i%50}",
                    "priority": i % 5,
                    "metadata": {
                        "batch_id": i // 1000,
                        "sequence": i % 1000
                    }
                }
            })

        for i in range(25000):
            massive_duplicate_list.append({
                "event_id": f"massive_duplicate_{i:06d}",
                "message": f"Massive duplicate event {i}",
                "timestamp": f"2025-01-01T{i%24:02d}:{i%60:02d}:{i%60:02d}Z",
                "data": {
                    "source": f"duplicate_source_{i%100}",
                    "category": f"duplicate_category_{i%50}",
                    "priority": i % 5
                }
            })

        mock_oase.bulksend.side_effect = [
            {"status": "success", "sent": 25000, "failure": 0, "processing_time_ms": 1500},
            {"status": "success", "sent": 25000, "failure": 0, "processing_time_ms": 1200}
        ]

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®š
        start_time = time.time()
        recieve_ret, duplicate_ret = add_notification_queue(
            wsdb_mock, massive_recieve_list, massive_duplicate_list
        )
        end_time = time.time()

        execution_time = end_time - start_time

        # çµæœæ¤œè¨¼
        assert recieve_ret["status"] == "success"
        assert recieve_ret["sent"] == 25000
        assert duplicate_ret["status"] == "success"
        assert duplicate_ret["sent"] == 25000

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã®ç¢ºèªï¼ˆä¾‹ï¼š10ç§’ä»¥å†…ã§å®Œäº†ï¼‰
        assert execution_time < 10.0, f"Execution took {execution_time:.2f} seconds, expected < 10.0"

        # OASE.bulksendãŒ2å›å‘¼ã°ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert mock_oase.bulksend.call_count == 2

    @pytest.mark.stress
    @patch('controllers.oase_controller.OASE')
    def test_memory_usage_with_large_datasets(self, mock_oase):
        """å¤§é‡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""
        import sys

        wsdb_mock = MagicMock()

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šé–‹å§‹
        initial_size = sys.getsizeof(locals())

        # éå¸¸ã«å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ
        huge_data = []
        for i in range(100000):
            huge_data.append({
                "event_id": f"huge_event_{i:07d}",
                "message": f"Huge event message {i} with additional content to increase memory usage",
                "large_field": "x" * 1000,  # 1KB ã®ãƒ‡ãƒ¼ã‚¿
                "nested_data": {
                    "level1": {"level2": {"level3": f"deep_value_{i}"}},
                    "array_data": list(range(100)),
                    "string_data": f"Additional string data for event {i}" * 10
                }
            })

        mock_oase.bulksend.return_value = {"status": "success", "sent": 100000, "failure": 0}

        # é–¢æ•°å®Ÿè¡Œ
        recieve_ret, duplicate_ret = add_notification_queue(
            wsdb_mock, huge_data, []
        )

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šçµ‚äº†
        final_size = sys.getsizeof(locals())
        memory_increase = final_size - initial_size

        # çµæœç¢ºèª
        assert recieve_ret["status"] == "success"
        assert recieve_ret["sent"] == 100000
        assert duplicate_ret == {}

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¦¥å½“ãªç¯„å›²å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        # ï¼ˆå®Ÿéš›ã®å€¤ã¯ç’°å¢ƒã«ã‚ˆã‚Šç•°ãªã‚‹ãŸã‚ã€å¤§ã¾ã‹ãªé–¾å€¤ã‚’è¨­å®šï¼‰
        assert memory_increase < 1000000000, f"Memory increase: {memory_increase} bytes"

    @patch('controllers.oase_controller.OASE')
    def test_concurrent_execution_simulation(self, mock_oase):
        """ä¸¦è¡Œå®Ÿè¡Œã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # è¤‡æ•°ã®åŒæ™‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        concurrent_requests = []

        for request_id in range(10):
            recieve_list = [
                {
                    "event_id": f"concurrent_{request_id}_{i}",
                    "message": f"Concurrent event {i} from request {request_id}",
                    "request_id": request_id
                }
                for i in range(100)
            ]
            duplicate_list = [
                {
                    "event_id": f"concurrent_dup_{request_id}_{i}",
                    "message": f"Concurrent duplicate {i} from request {request_id}",
                    "request_id": request_id
                }
                for i in range(50)
            ]
            concurrent_requests.append((recieve_list, duplicate_list))

        # å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã«å¯¾ã™ã‚‹å¿œç­”ã‚’è¨­å®š
        mock_responses = []
        for i in range(20):  # 10ãƒªã‚¯ã‚¨ã‚¹ãƒˆ Ã— 2å›ã®å‘¼ã³å‡ºã—
            mock_responses.append({"status": "success", "sent": 100 if i % 2 == 0 else 50, "failure": 0})

        mock_oase.bulksend.side_effect = mock_responses

        # å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é †æ¬¡å®Ÿè¡Œï¼ˆä¸¦è¡Œå®Ÿè¡Œã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼‰
        results = []
        for recieve_list, duplicate_list in concurrent_requests:
            recieve_ret, duplicate_ret = add_notification_queue(
                wsdb_mock, recieve_list, duplicate_list
            )
            results.append((recieve_ret, duplicate_ret))

        # å…¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã—ãŸã“ã¨ã‚’ç¢ºèª
        assert len(results) == 10
        for recieve_ret, duplicate_ret in results:
            assert recieve_ret["status"] == "success"
            assert recieve_ret["sent"] == 100
            assert duplicate_ret["status"] == "success"
            assert duplicate_ret["sent"] == 50

        # åˆè¨ˆ20å›ã®å‘¼ã³å‡ºã—ãŒè¡Œã‚ã‚ŒãŸã“ã¨ã‚’ç¢ºèª
        assert mock_oase.bulksend.call_count == 20

    @pytest.mark.stress
    @patch('controllers.oase_controller.OASE')
    @patch('controllers.oase_controller.stacktrace')
    def test_error_rate_under_stress(self, mock_stacktrace, mock_oase):
        """ã‚¹ãƒˆãƒ¬ã‚¹ä¸‹ã§ã®ã‚¨ãƒ©ãƒ¼ç‡ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # 1000å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§10%ã®ã‚¨ãƒ©ãƒ¼ç‡ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        total_requests = 1000
        error_rate = 0.1

        # å¿œç­”ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¨­å®šï¼ˆæˆåŠŸã¨ã‚¨ãƒ©ãƒ¼ã®æ··åœ¨ï¼‰
        responses = []
        for i in range(total_requests * 2):  # å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§2å›ã®å‘¼ã³å‡ºã—
            if i % 10 == 0:  # 10%ã®ã‚¨ãƒ©ãƒ¼ç‡
                responses.append(ConnectionError(f"Simulated error {i}"))
            else:
                responses.append({"status": "success", "sent": 1, "failure": 0})

        mock_oase.bulksend.side_effect = responses
        mock_stacktrace.return_value = "Stress test stack trace"

        # çµ±è¨ˆåé›†
        success_count = 0
        error_count = 0

        # å¤§é‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å®Ÿè¡Œ
        for i in range(total_requests):
            recieve_list = [{"event_id": f"stress_{i}", "message": f"Stress event {i}"}]
            duplicate_list = []

            try:
                recieve_ret, duplicate_ret = add_notification_queue(
                    wsdb_mock, recieve_list, duplicate_list
                )

                # æˆåŠŸã®å ´åˆ
                if recieve_ret and recieve_ret.get("status") == "success":
                    success_count += 1
                else:
                    error_count += 1

            except Exception:
                error_count += 1

        # ã‚¨ãƒ©ãƒ¼ç‡ã®æ¤œè¨¼
        actual_error_rate = error_count / total_requests

        # è¨±å®¹ç¯„å›²å†…ã®ã‚¨ãƒ©ãƒ¼ç‡ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆÂ±2%ã®èª¤å·®ã‚’è¨±å®¹ï¼‰
        assert abs(actual_error_rate - error_rate) < 0.02, f"Error rate: {actual_error_rate:.2%}, expected: {error_rate:.2%}"

        # æˆåŠŸã—ãŸãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚‚ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert success_count > 0, "No successful requests under stress"

    @patch('controllers.oase_controller.OASE')
    def test_response_time_distribution(self, mock_oase):
        """å¿œç­”æ™‚é–“åˆ†å¸ƒãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # æ§˜ã€…ãªå¿œç­”æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        response_times = []

        def slow_oase_bulksend(*args, **kwargs):
            """OASE.bulksendã®é…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ"""
            import random
            # 0.1-2.0ç§’ã®é…å»¶ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ç™ºç”Ÿ
            delay = random.uniform(0.1, 2.0)
            time.sleep(delay)
            response_times.append(delay)
            return {"status": "success", "sent": 1, "failure": 0, "response_time": delay}

        mock_oase.bulksend.side_effect = slow_oase_bulksend

        # 100å›ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        execution_times = []

        for i in range(100):
            event_list = [{"event_id": f"timing_{i}", "message": f"Timing event {i}"}]

            start_time = time.time()
            recieve_ret, duplicate_ret = add_notification_queue(
                wsdb_mock, event_list, []
            )
            end_time = time.time()

            execution_times.append(end_time - start_time)

            # å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert recieve_ret["status"] == "success"

        # çµ±è¨ˆè¨ˆç®—
        avg_execution_time = sum(execution_times) / len(execution_times)
        max_execution_time = max(execution_times)
        min_execution_time = min(execution_times)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¦ä»¶ã®ç¢ºèª
        assert avg_execution_time < 3.0, f"Average execution time: {avg_execution_time:.2f}s"
        assert max_execution_time < 5.0, f"Maximum execution time: {max_execution_time:.2f}s"
        assert min_execution_time > 0.05, f"Minimum execution time: {min_execution_time:.2f}s"

    @patch('controllers.oase_controller.OASE')
    def test_memory_leak_detection(self, mock_oase):
        """ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        import gc

        wsdb_mock = MagicMock()
        mock_oase.bulksend.return_value = {"status": "success", "sent": 1, "failure": 0}

        # åˆæœŸãƒ¡ãƒ¢ãƒªçŠ¶æ…‹
        gc.collect()
        initial_objects = len(gc.get_objects())

        # å¤§é‡ã®ç¹°ã‚Šè¿”ã—å®Ÿè¡Œ
        for i in range(1000):
            event_list = [
                {
                    "event_id": f"leak_test_{i}",
                    "message": f"Memory leak test event {i}",
                    "large_data": "x" * 1000  # 1KB ã®ãƒ‡ãƒ¼ã‚¿
                }
            ]

            recieve_ret, duplicate_ret = add_notification_queue(
                wsdb_mock, event_list, []
            )

            # å®šæœŸçš„ãªã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
            if i % 100 == 0:
                gc.collect()
                _final_objects = len(gc.get_objects())
                object_increase = _final_objects - initial_objects
                print(f"progress increase: {_final_objects} - {initial_objects} = {object_increase}")

        # æœ€çµ‚ãƒ¡ãƒ¢ãƒªçŠ¶æ…‹
        gc.collect()
        final_objects = len(gc.get_objects())

        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆæ•°ã®å¢—åŠ ã‚’ãƒã‚§ãƒƒã‚¯
        object_increase = final_objects - initial_objects
        print(f"Object increase: {final_objects} - {initial_objects} = {object_increase}")

        # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ãŒãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆå°‘ã—ã®å¢—åŠ ã¯è¨±å®¹ï¼‰
        # g.applogger.info å‘¼ã¶ã ã‘ã§ã‚‚å¢—åŠ ã™ã‚‹ã®ã§ã€é–¾å€¤ã‚’é«˜ã‚ã«è¨­å®š(è¿½åŠ :*10*2)
        assert object_increase < 1000 * 10 * 2, f"Potential memory leak detected: {object_increase} objects increased"

        # å…¨ã¦ã®å‘¼ã³å‡ºã—ãŒæˆåŠŸã—ãŸã“ã¨ã‚’ç¢ºèª
        assert mock_oase.bulksend.call_count == 1000


class TestSpecialInputPatterns:
    """ç‰¹æ®Šãªå…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒ†ã‚¹ãƒˆ"""

    def setup_method(self):
        """å„ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®å‰ã«å®Ÿè¡Œã•ã‚Œã‚‹åˆæœŸåŒ–å‡¦ç†"""
        self.app = Flask(__name__)
        self.app_context = self.app.app_context()
        self.app_context.push()

        g.applogger = MagicMock()
        g.appmsg = MagicMock()
        g.applogger.info = MagicMock()
        g.applogger.warning = MagicMock()
        g.applogger.error = MagicMock()

    def teardown_method(self):
        """å„ãƒ†ã‚¹ãƒˆãƒ¡ã‚½ãƒƒãƒ‰ã®å¾Œã«å®Ÿè¡Œã•ã‚Œã‚‹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        self.app_context.pop()

    @patch('controllers.oase_controller.OASE')
    def test_binary_data_handling(self, mock_oase):
        """ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ã‚¤ãƒ™ãƒ³ãƒˆ
        binary_events = [
            {
                "event_id": "binary_test",
                "message": "Event with binary data",
                "binary_field": b'\x00\x01\x02\x03\x04\x05',
                "base64_data": "SGVsbG8gV29ybGQ="  # "Hello World" in base64
            }
        ]

        mock_oase.bulksend.return_value = {"status": "success", "sent": 1, "failure": 0}

        recieve_ret, duplicate_ret = add_notification_queue(
            wsdb_mock, binary_events, []
        )

        assert recieve_ret["status"] == "success"
        assert duplicate_ret == {}

        # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãæ¸¡ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        call_args = mock_oase.bulksend.call_args[0]
        passed_data = call_args[1][0]
        assert passed_data["binary_field"] == b'\x00\x01\x02\x03\x04\x05'
        assert passed_data["base64_data"] == "SGVsbG8gV29ybGQ="

    @patch('controllers.oase_controller.OASE')
    def test_circular_reference_handling(self, mock_oase):
        """å¾ªç’°å‚ç…§å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # å¾ªç’°å‚ç…§ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        circular_data = {"id": "circular_test"}
        circular_data["self_ref"] = circular_data  # å¾ªç’°å‚ç…§

        events_with_circular_ref = [
            {
                "event_id": "circular_ref_test",
                "message": "Event with circular reference",
                "circular_data": circular_data
            }
        ]

        mock_oase.bulksend.return_value = {"status": "success", "sent": 1, "failure": 0}

        # å¾ªç’°å‚ç…§ãŒã‚ã£ã¦ã‚‚ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãªã„ã“ã¨ã‚’ç¢ºèª
        recieve_ret, duplicate_ret = add_notification_queue(
            wsdb_mock, events_with_circular_ref, []
        )

        assert recieve_ret["status"] == "success"
        assert duplicate_ret == {}

    @patch('controllers.oase_controller.OASE')
    def test_extreme_unicode_handling(self, mock_oase):
        """æ¥µç«¯ãªUnicodeæ–‡å­—å‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        wsdb_mock = MagicMock()

        # æ§˜ã€…ãªUnicodeæ–‡å­—ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
        unicode_events = [
            {
                "event_id": "unicode_test",
                "message": "ğŸŒˆğŸ¦„ğŸ’«âœ¨ğŸ­ğŸªğŸ¨ğŸ¯ğŸ²ğŸ®ğŸ¤ğŸ§ğŸ¼ğŸ¹ğŸ¸ğŸºğŸ·",
                "emoji_field": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘®â€â™€ï¸ğŸ‘·â€â™‚ï¸ğŸ’‚â€â™€ï¸ğŸ•µï¸â€â™‚ï¸ğŸ‘©â€âš•ï¸ğŸ‘¨â€ğŸŒ¾ğŸ‘©â€ğŸ³ğŸ‘¨â€ğŸ“",
                "mathematical": "âˆ‘âˆâˆ«âˆ†âˆ‡âˆ‚âˆâ‰ˆâ‰ â‰¤â‰¥Â±âˆ“Ã—Ã·âˆšâˆ›âˆœâˆ âˆŸâŠ¥âˆ¥âŠ•âŠ—âŠ™âŠ†âŠ‡âŠ‚âŠƒ",
                "currency": "â‚¿â‚¹â‚½â‚´â‚¨â‚©â‚ªâ‚«â‚¦â‚¡â‚¨â‚±â‚µâ‚¸â‚¼â‚½â‚¾â‚¿ï¼„ï¿ ï¿¡ï¿¢ï¿£ï¿¤ï¿¥ï¿¦",
                "arrows": "â†â†‘â†’â†“â†”â†•â†–â†—â†˜â†™â‡â‡‘â‡’â‡“â‡”â‡•â‡–â‡—â‡˜â‡™âŸµâŸ¶âŸ·âŸ¸âŸ¹âŸº",
                "chinese": "ä¸­æ–‡æµ‹è¯•æ•°æ®åŒ…å«å„ç§æ±‰å­—å­—ç¬¦é›†",
                "arabic": "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù…Ø®ØªÙ„ÙØ©",
                "cyrillic": "Ğ¢ĞµÑÑ‚Ğ¾Ğ²Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° ĞºĞ¸Ñ€Ğ¸Ğ»Ğ»Ğ¸Ñ†Ğµ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¼Ğ¸ Ğ½Ğ°Ğ±Ğ¾Ñ€Ğ°Ğ¼Ğ¸ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²"
            }
        ]

        mock_oase.bulksend.return_value = {"status": "success", "sent": 1, "failure": 0}

        recieve_ret, duplicate_ret = add_notification_queue(
            wsdb_mock, unicode_events, []
        )

        assert recieve_ret["status"] == "success"
        assert duplicate_ret == {}

        # Unicodeæ–‡å­—ãŒæ­£ã—ãä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        call_args = mock_oase.bulksend.call_args[0]
        passed_data = call_args[1][0]
        assert "ğŸŒˆğŸ¦„ğŸ’«âœ¨" in passed_data["message"]
        assert "ä¸­æ–‡æµ‹è¯•" in passed_data["chinese"]
